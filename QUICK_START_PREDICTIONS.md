# Quick Start - Sistema de PredicciÃ³n

## ðŸš€ Usa el Sistema AHORA (5 minutos)

### OpciÃ³n 1: Workflow Completo AutomÃ¡tico

```powershell
# Ejecuta el ejemplo completo
python example_complete_workflow.py
```

Esto generarÃ¡ predicciones de ejemplo para 4 partidos y te mostrarÃ¡:
- âœ… Predicciones con confidence scoring
- âœ… Recomendaciones BET/SKIP
- âœ… Expected goals
- âœ… Resumen de insights accionables

**Output:** `data/predictions/example_predictions_GW23.csv`

---

### OpciÃ³n 2: PredicciÃ³n Manual Paso a Paso

#### Paso 1: Crear Fixtures (Input Manual)

```powershell
python scripts/get_upcoming_fixtures.py --manual
```

Ingresa tus fixtures:
```
> 2026-01-11,Arsenal,Man City,23
> 2026-01-11,Newcastle,Fulham,23
> [Enter dos veces]
```

**Output:** `data/raw/upcoming_fixtures_GW23_20260104.csv`

#### Paso 2: Construir Dataset con Features V2

```powershell
python scripts/build_prediction_dataset.py \
    --input data/raw/upcoming_fixtures_GW23_20260104.csv \
    --gameweek 23
```

**Output:** `data/predictions/prediction_data_GW23_{timestamp}.parquet`

#### Paso 3: Generar Predicciones

```powershell
python scripts/predict_fixtures.py \
    --input data/predictions/prediction_data_GW23_*.parquet \
    --threshold 0.62 \
    --min-confidence 70
```

**Output:** `data/predictions/predictions_{timestamp}.csv`

#### Paso 4: Ver Resultados

```powershell
cat data/predictions/predictions_*.csv
```

O abre el CSV en Excel/Google Sheets.

---

## âš¡ Comandos One-Liner

### PredicciÃ³n RÃ¡pida (Manual Input)

```powershell
python scripts/get_upcoming_fixtures.py --manual && python scripts/build_prediction_dataset.py --input data/raw/upcoming_fixtures_*.csv --gameweek 23 && python scripts/predict_fixtures.py --input data/predictions/prediction_data_GW23_*.parquet --threshold 0.62
```

### Backtest RÃ¡pido (Validar Sistema)

```powershell
# Validar Ãºltimas 5 jornadas
python scripts/backtest_predictions.py --start-gameweek 18 --end-gameweek 22 --min-confidence 70
```

Esto te dirÃ¡:
- âœ… Accuracy real del sistema
- âœ… ROI simulado
- âœ… Si el modelo funciona bien

---

## ðŸ“Š Interpretar Resultados

### Archivo CSV de Predicciones

```csv
fixture_id,date,home_team,away_team,prob_over,prediction_label,confidence,recommendation
GW23_ARS_MCI,2026-01-11,Arsenal,Man City,0.72,Over 2.5,85,"BET: Over 2.5 (High Confidence)"
```

**Columnas importantes:**
- `prob_over`: Probabilidad de Over 2.5 segÃºn el modelo
- `confidence`: Confiabilidad 0-100%
- `recommendation`: AcciÃ³n sugerida

### CÃ³mo Actuar

#### Confidence â‰¥ 80% (Very High)
```
Arsenal vs Man City | Over 2.5 (72%) | Confidence: 85%
â†’ ACCIÃ“N: Apostar con confianza (stake normal)
```

#### Confidence 65-79% (High/Medium)
```
Newcastle vs Fulham | Under 2.5 (58%) | Confidence: 72%
â†’ ACCIÃ“N: Apostar con cautela (stake reducido)
```

#### Confidence < 65% (Low)
```
Tottenham vs Brentford | Over 2.5 (52%) | Confidence: 41%
â†’ ACCIÃ“N: NO apostar (muy incierto)
```

---

## ðŸ”§ Antes de Usar en ProducciÃ³n

### 1. Optimizar Threshold (IMPORTANTE)

El threshold default del modelo (0.75) es muy conservador. OptimÃ­zalo:

```powershell
python scripts/optimize_threshold_production.py \
    --metric custom \
    --target-sensitivity 0.55 \
    --target-specificity 0.60 \
    --save-model
```

**Output:**
- Threshold Ã³ptimo: ~0.62-0.65
- Modelo guardado: `models/production_model_optimized_*.pkl`

Luego usa el modelo optimizado:
```powershell
python scripts/predict_fixtures.py \
    --model models/production_model_optimized_*.pkl \
    --input data/predictions/prediction_data_GW23.parquet
```

### 2. Validar con Backtest

```powershell
# Simular predicciones de jornadas pasadas
python scripts/backtest_predictions.py --start-gameweek 18 --end-gameweek 22

# Output: models/results/backtest_report_*.csv
```

**MÃ©tricas esperadas:**
- Accuracy: 55-65%
- ROI: Positivo (esperanza: +5% to +15%)
- Calibration error: < 0.10

**Si backtest falla** (accuracy < 50% o ROI negativo):
- âŒ NO uses el sistema aÃºn
- âœ… Re-entrena modelo con datos mÃ¡s recientes
- âœ… Ajusta min-confidence mÃ¡s alto (75-80%)

### 3. Ajustar Confidence Threshold

Basado en backtest:

```
Si backtest muestra:
  ROI positivo con confidence â‰¥ 70% â†’ Usar --min-confidence 70
  ROI negativo con confidence â‰¥ 70% â†’ Subir a --min-confidence 75
  ROI positivo solo con confidence â‰¥ 80% â†’ Usar --min-confidence 80
```

---

## â“ Troubleshooting RÃ¡pido

### Error: "Feature X not found"
```powershell
# SoluciÃ³n: Verificar que usas datos V2
python check_features.py
```

### Predicciones todas "Over" o todas "Under"
```powershell
# SoluciÃ³n: Optimizar threshold
python scripts/optimize_threshold_production.py --save-model
```

### Confidence scores muy bajos (<50%)
```powershell
# Posible data drift alto
# SoluciÃ³n: Re-entrenar modelo
python scripts/retrain_improved_pipeline.py --seasons 2425 2526
```

### Error: "Model not found"
```powershell
# SoluciÃ³n: Verificar ruta del modelo
ls models/results/

# Si no existe, re-entrenar:
python scripts/retrain_improved_pipeline.py --models poisson_balanced
```

---

## ðŸ“ Archivos Importantes

### Inputs
- `data/raw/upcoming_fixtures_*.csv` - Fixtures futuros
- `data/final/training_data_v2.parquet` - Datos histÃ³ricos con V2 features

### Outputs
- `data/predictions/prediction_data_*.parquet` - Dataset con features
- `data/predictions/predictions_*.csv` - Predicciones finales (ABRIR ESTO)

### Models
- `models/results/retrain_checkpoint.pkl` - Modelo entrenado
- `models/production_model_optimized_*.pkl` - Modelo con threshold optimizado

### Logs
- `logs/retrain_*.log` - Logs de entrenamiento
- `logs/app.log` - Logs generales

---

## ðŸŽ¯ Workflow Recomendado (Semanal)

### Lunes/Martes (Antes de Fixtures)
```powershell
# 1. Obtener fixtures de prÃ³xima jornada
python scripts/get_upcoming_fixtures.py --manual  # O desde API

# 2. Generar dataset
python scripts/build_prediction_dataset.py --input data/raw/upcoming_fixtures_*.csv

# 3. Predecir
python scripts/predict_fixtures.py --input data/predictions/prediction_data_*.parquet --threshold 0.62 --min-confidence 70

# 4. Revisar CSV y hacer apuestas
cat data/predictions/predictions_*.csv
```

### Fin de Semana (DespuÃ©s de Resultados)
```powershell
# 1. Comparar predicciones vs resultados reales
# 2. Calcular ROI real
# 3. Ajustar confidence thresholds si es necesario
```

### Mensual
```powershell
# Re-entrenar modelo con datos frescos
python scripts/retrain_improved_pipeline.py --seasons 2425 2526

# Re-optimizar threshold
python scripts/optimize_threshold_production.py --save-model
```

---

## ðŸ“š DocumentaciÃ³n Completa

- `PREDICTION_SYSTEM_GUIDE.md` - GuÃ­a maestra completa
- `DASHBOARD_SETUP.md` - Setup del dashboard
- `README.md` - VisiÃ³n general del proyecto

---

## âœ… Checklist Antes de Primera PredicciÃ³n Real

- [ ] âœ“ Optimizar threshold (`optimize_threshold_production.py`)
- [ ] âœ“ Hacer backtest (`backtest_predictions.py --start-gameweek 18 --end-gameweek 22`)
- [ ] âœ“ Verificar backtest accuracy â‰¥ 55%
- [ ] âœ“ Verificar backtest ROI positivo
- [ ] âœ“ Ajustar min-confidence basado en backtest
- [ ] âœ“ Hacer predicciÃ³n de prueba con `example_complete_workflow.py`
- [ ] âœ“ Empezar con stakes pequeÃ±os (10-20% de capital normal)
- [ ] âœ“ Hacer solo 2-3 apuestas la primera semana
- [ ] âœ“ Registrar resultados para anÃ¡lisis posterior

---

**Â¡Listo para empezar!** ðŸš€âš½

Ejecuta:
```powershell
python example_complete_workflow.py
```

Y tendrÃ¡s tus primeras predicciones en menos de 1 minuto.
